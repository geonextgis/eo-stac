{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<a href=\"https://githubtocolab.com/geonextgis/eo-stac/blob/main/notebooks/intro_to_stac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
    "\n",
    "# The STAC API Workflow\n",
    "\n",
    "**Author:** Krishnagopal Halder\n",
    "\n",
    "**Objective:** Learn to Search, Stream, and Download satellite imagery using Python and the STAC [(SpatioTemporal Asset Catalog)](https://stacspec.org/en/) standard.\n",
    "\n",
    "**What you will learn**\n",
    "1. **Discovery:** How to find specific satellite scenes without downloading them.\n",
    "\n",
    "2. **Cloud-Native Analysis:** How to stream pixels directly to RAM for immediate analysis (NDVI).\n",
    "\n",
    "3. **Bulk Download:** How to download raw files to disk for archival purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install pystac-client odc-stac rioxarray pandas matplotlib netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "from odc.stac import load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Step 2: Discovery (The Search)\n",
    "We will search the [Earth Search v1 (AWS)](https://stacindex.org/catalogs/earth-search#/) catalog. This is a public API that indexes free data like Sentinel-2 and Landsat.\n",
    "\n",
    "**Concept:** At this stage, we are only querying Metadata (JSON). We are filtering the library catalog to find the \"books\" we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the STAC Catalog\n",
    "API_URL = \"https://earth-search.aws.element84.com/v1/\"\n",
    "client = pystac_client.Client.open(API_URL)\n",
    "\n",
    "# Get the collections available\n",
    "collections = client.get_collections()\n",
    "\n",
    "for col in collections:\n",
    "    print(col.id, \":\", col.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Parameters\n",
    "# Region: San Francisco Bay Area\n",
    "bbox = [-122.55, 37.7, -122.35, 37.85]\n",
    "\n",
    "# # 3. Define date range\n",
    "date_range = \"2023-06-01/2023-09-30\"\n",
    "\n",
    "# Collection: Sentinel-2 Level 2A (Surface Reflectance)\n",
    "collection = \"sentinel-2-l2a\"\n",
    "\n",
    "# Execute search\n",
    "search = client.search(\n",
    "    collections=[collection],\n",
    "    bbox=bbox,\n",
    "    datetime=date_range,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}},  # Filter: Less than 10% clouds\n",
    ")\n",
    "\n",
    "# Check results\n",
    "items = search.item_collection()\n",
    "print(f\"Found {len(items)} scenes matching your criteria.\")\n",
    "\n",
    "# Peek at the first item found\n",
    "first_item = items[0]\n",
    "print(f\"Example Item ID: {first_item.id}\")\n",
    "print(f\"Captured on: {first_item.datetime.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "**Understanding \"Assets\"**\n",
    "\n",
    "A single STAC Item (one scene) contains multiple Assets. These are the actual files. Let's look at what is inside one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the available assets for the first item\n",
    "assets_df = pd.DataFrame.from_dict(first_item.assets, orient=\"index\").reset_index()\n",
    "assets_df.columns = [\"asset\", \"href\"]\n",
    "print(assets_df.shape)\n",
    "assets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 2: Cloud-Native Analysis (Streaming)\n",
    "**The Modern Workflow:** instead of downloading the files shown above, we use Cloud Optimized GeoTIFFs (COGs). We can stream just the pixels inside our bounding box directly into an xarray DataArray.\n",
    "\n",
    "**Goal:** Calculate NDVI (Normalized Difference Vegetation Index) for vegetation health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data into Memory (Lazy Loading)\n",
    "# We request only the Red and Near-Infrared (NIR) bands needed for NDVI\n",
    "data = load(\n",
    "    items,\n",
    "    bands=[\"red\", \"nir\"],\n",
    "    bbox=bbox,\n",
    "    resolution=10,  # Sentinel-2 resolution is 10m\n",
    "    group_by=\"solar_day\",  # Combine segments from the same day,\n",
    "    chunks={\"x\": 2048, \"y\": 2048},  # Use Dask for parallel processing\n",
    ")\n",
    "\n",
    "print(\"Data Cube Structure (No pixels downloaded yet):\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scale factor\n",
    "data = data / 1e4\n",
    "\n",
    "# Perform Math (NDVI Calculation)\n",
    "# Formula: (NIR - Red) / (NIR + Red)\n",
    "ndvi = (data.nir - data.red) / (data.nir + data.red)\n",
    "\n",
    "# Compute and visualize\n",
    "# We select the first time step available in our search\n",
    "print(\"Streaming pixels and plotting... this may take 10-20 seconds.\")\n",
    "ndvi_snapshot = ndvi.isel(time=0).compute()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ndvi_snapshot.plot.imshow(cmap=\"RdYlGn\", robust=True)\n",
    "plt.title(f\"NDVI: {data.time[0].dt.date.item()}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 3: Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Single Snapshot as a GeoTIFF\n",
    "# Ensure the CRS (Coordinate Reference System) is written to the metadata\n",
    "ndvi_snapshot.rio.write_crs(data.spatial_ref.item(), inplace=True)\n",
    "\n",
    "# Save to disk\n",
    "ndvi_snapshot.rio.to_raster(\"ndvi_snapshot.tif\")\n",
    "print(\"Saved ndvi_snapshot.tif successfully\")\n",
    "\n",
    "# Save the whole Time-Series as NetCDF\n",
    "ndvi.rio.write_crs(data.spatial_ref.item(), inplace=True)\n",
    "ndvi.to_netcdf(\"ndvi_timeseries.nc\", engine=\"netcdf4\")\n",
    "print(\"Saved ndvi_timeseries.nc successfuly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
